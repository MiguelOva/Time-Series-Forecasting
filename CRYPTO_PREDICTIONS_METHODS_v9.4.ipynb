{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "02d03bde",
   "metadata": {
    "id": "02d03bde"
   },
   "source": [
    "# Crypto Currencies - Time Series Forecasting\n",
    "# <font color='blue'>0. Identification for Business Requirements</font> <a class=\"anchor\" id=\"first-bullet\"></a>\n",
    "\n",
    "### A Short Description About the Dataset & It's Source\n",
    "\n",
    "\n",
    "####  Dataset of Bitcoin Historical Data\n",
    "\n",
    "## <font color= blue >1. Importing the Necessary Libraries</font> <a class=\"anchor\" id=\"second-bullet\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d2f5110",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Implement Hyperparameter tunning on the available models.\n",
    "\n",
    "# Start on creating the classes for the Hybrid Models\n",
    "# Exponential Smoothing (ES)\n",
    "# Multi-Layer Perceptron (MLP) \n",
    "# Recurrent Neural Network (RNN) \n",
    "# Temporal Fusion Transformer (TFT - Google)\n",
    "# DeepAR\n",
    "# N-BEATS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "UIGl_AdDuMjB",
   "metadata": {
    "id": "UIGl_AdDuMjB",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!pip install cryptocmd\n",
    "#!pip install arch\n",
    "#!pip install prophet\n",
    "#!pip install torch\n",
    "#!pip install tensorflow\n",
    "#!pip install keras-tuner\n",
    "#!pip install lightgbm\n",
    "#!pip install xgboost\n",
    "#!pip install prettytable\n",
    "#!pip install bokeh\n",
    "#!pip install pmdarima\n",
    "#!pip uninstall statsmodels --y\n",
    "#%pip install torch\n",
    "#%pip install pytorch-forecasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1074ec0f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Standard library imports\n",
    "import os\n",
    "import time\n",
    "import warnings\n",
    "import sys\n",
    "import requests\n",
    "import pickle\n",
    "import logging\n",
    "import joblib\n",
    "\n",
    "\n",
    "# Third party imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Data Preprocessing and Analysis\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "from statsmodels.tsa.stattools import adfuller, grangercausalitytests\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from cryptocmd import CmcScraper\n",
    "\n",
    "# Deep Learning and Machine Learning Libraries\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, LSTM, TimeDistributed, Conv1D, MaxPooling1D, Flatten\n",
    "from keras.optimizers import Adam, SGD\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.layers import ConvLSTM2D\n",
    "from kerastuner.tuners import RandomSearch\n",
    "from kerastuner import HyperModel\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from lightgbm import LGBMRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "\n",
    "\n",
    "# Metrics and Model Evaluation\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score, accuracy_score, explained_variance_score\n",
    "from prettytable import PrettyTable\n",
    "\n",
    "# Plotting and Visualization\n",
    "\"\"\"from bokeh.plotting import figure, show\n",
    "from bokeh.models import HoverTool, ColumnDataSource, WheelZoomTool, Span, Range1d\n",
    "from bokeh.layouts import column\n",
    "from bokeh.models.widgets import Button\n",
    "from bokeh.models.callbacks import CustomJS\n",
    "from bokeh.themes import Theme\"\"\"\n",
    "\n",
    "# Time Series Analysis and Forecasting\n",
    "import pmdarima as pm\n",
    "from arch import arch_model\n",
    "\n",
    "# Miscellaneous\n",
    "from joblib import dump, load\n",
    "from math import pi\n",
    "\n",
    "# Warnings and Logging\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option('display.float_format', '{:.3f}'.format)\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s [%(levelname)s] - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b94427a8",
   "metadata": {},
   "source": [
    "# Block 1. - CryptoDate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68105fa0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CryptoData:\n",
    "    \"\"\"\n",
    "    This class is responsible for fetching and formatting cryptocurrency data.\n",
    "\n",
    "    Input:\n",
    "        crypto_symbol (str): The symbol of the cryptocurrency, e.g., \"BTC\" for Bitcoin.\n",
    "\n",
    "    Methods:\n",
    "        get_cryptocmd_data: Fetches cryptocurrency data and returns a formatted DataFrame.\n",
    "        get_display_data: Fetches and formats cryptocurrency data for display purposes.\n",
    "    \"\"\"\n",
    "    def __init__(self, crypto_symbol: str):\n",
    "        logging.info(\"Initializing CryptoData class\")\n",
    "        self.crypto_symbol = crypto_symbol\n",
    "\n",
    "    def _fetch_cryptocmd_data(self) -> pd.DataFrame:\n",
    "        logging.info(f\"Fetching {self.crypto_symbol} data\")\n",
    "        try:\n",
    "            scraper = CmcScraper(self.crypto_symbol)\n",
    "            df = scraper.get_dataframe()\n",
    "            if not {'Date', 'Open', 'High', 'Low', 'Close', 'Market Cap', 'Volume'}.issubset(df.columns):\n",
    "                raise ValueError(\"Some expected columns are missing in the data.\")\n",
    "            logging.info(f\"Data fetched successfully for {self.crypto_symbol}\")\n",
    "            return df\n",
    "        except Exception as e:\n",
    "            logging.error(f'An error occurred while fetching data: {e}')\n",
    "            raise  # Propagate the exception\n",
    "\n",
    "    def get_cryptocmd_data(self) -> pd.DataFrame:\n",
    "        logging.info(f\"Getting {self.crypto_symbol} data\")\n",
    "        df = self._fetch_cryptocmd_data()\n",
    "        df.set_index('Date', inplace=True)\n",
    "        df.index = pd.to_datetime(df.index)\n",
    "        logging.info(f\"Data obtained successfully for {self.crypto_symbol}\")\n",
    "        return df.round(2)\n",
    "\n",
    "    @staticmethod\n",
    "    def _format_monetary_value(value: float) -> str:\n",
    "        return \"${:,.2f}\".format(value)\n",
    "\n",
    "    @staticmethod\n",
    "    def _format_volume_value(value: float) -> str:\n",
    "        if value > 1e9:\n",
    "            return \"{:.2f}B\".format(value/1e9)\n",
    "        elif value > 1e6:\n",
    "            return \"{:.2f}M\".format(value/1e6)\n",
    "        else:\n",
    "            return \"{:,.2f}\".format(value)\n",
    "\n",
    "    def get_display_data(self) -> pd.DataFrame:\n",
    "        logging.info(f\"Formatting display data for {self.crypto_symbol}\")\n",
    "        display_df = self.get_cryptocmd_data().copy()\n",
    "        monetary_columns = ['Open', 'High', 'Low', 'Close']\n",
    "        display_df[monetary_columns] = display_df[monetary_columns].applymap(self._format_monetary_value)\n",
    "\n",
    "        # Check and apply volume formatting only if they are of numeric type\n",
    "        volume_like_columns = ['Volume', 'Market Cap']\n",
    "        for column in volume_like_columns:\n",
    "            if pd.api.types.is_numeric_dtype(display_df[column]):\n",
    "                display_df[column] = display_df[column].apply(self._format_volume_value)\n",
    "\n",
    "        logging.info(f\"Display data formatted successfully for {self.crypto_symbol}\")\n",
    "        return display_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d59dc48",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "crypto = CryptoData(\"BTC\")\n",
    "data = crypto.get_cryptocmd_data()\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc28242a",
   "metadata": {},
   "source": [
    "# ------------------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdd5cad3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Block 2 - Crypto analytics\n",
    "class CryptoAnalytics:\n",
    "    \"\"\"\n",
    "    This class is responsible for performing analytics on cryptocurrency data.\n",
    "\n",
    "    Input:\n",
    "        df (pd.DataFrame): The DataFrame containing the cryptocurrency data.\n",
    "\n",
    "    Methods:\n",
    "        get_all_time_records: Returns the all-time high and low closing prices.\n",
    "        get_yearly_analysis: Returns yearly high, low, average, and variation.\n",
    "        get_monthly_analysis: Returns monthly high, low, average, and variation.\n",
    "        get_weekly_analysis: Returns weekly high, low, average, and variation.\n",
    "    \"\"\"\n",
    "    def __init__(self, crypto_data: CryptoData):\n",
    "        logger.info(\"Initializing CryptoAnalytics class\")\n",
    "        self.df = crypto_data.get_cryptocmd_data()\n",
    "\n",
    "    def format_and_round(self, number):\n",
    "        return f'{number:,.2f}'\n",
    "\n",
    "    def apply_custom_formatting(self, data):\n",
    "        logger.info(\"Applying custom formatting\")\n",
    "        ordered_columns = [\n",
    "            'Open_first', 'Close_last', 'variation_$_abs',\n",
    "            'variation_%_rel', 'Close_min', 'Close_mean', 'Close_max'\n",
    "        ]\n",
    "        data = data[ordered_columns]\n",
    "        return data\n",
    "\n",
    "    def get_all_time_records(self):\n",
    "        logger.info(\"Getting all time records\")\n",
    "        all_time_high = self.df['Close'].max()\n",
    "        all_time_low = self.df['Close'].min()\n",
    "        all_time_high_date = self.df['Close'].idxmax().strftime('%Y-%m-%d')\n",
    "        all_time_low_date = self.df['Close'].idxmin().strftime('%Y-%m-%d')\n",
    "        return all_time_high, all_time_low, all_time_high_date, all_time_low_date\n",
    "\n",
    "    def get_yearly_analysis(self):\n",
    "        logger.info(\"Getting yearly analysis\")\n",
    "        yearly_data = self.df.resample('Y').agg({'Close': ['last', 'mean', 'max', 'min'], 'Open': 'first'})\n",
    "        yearly_data.columns = yearly_data.columns.map('_'.join).str.strip('_')\n",
    "        yearly_data = self.calculate_variation(yearly_data)\n",
    "        return self.apply_custom_formatting(yearly_data)\n",
    "\n",
    "    def get_monthly_analysis(self):\n",
    "        logger.info(\"Getting monthly analysis\")\n",
    "        monthly_data = self.df.resample('M').agg({'Close': ['last', 'mean', 'max', 'min'], 'Open': 'first'})\n",
    "        monthly_data.columns = monthly_data.columns.map('_'.join).str.strip('_')\n",
    "        monthly_data = self.calculate_variation(monthly_data)\n",
    "        return self.apply_custom_formatting(monthly_data)\n",
    "\n",
    "    def get_weekly_analysis(self):\n",
    "        logger.info(\"Getting weekly analysis\")\n",
    "        weekly_data = self.df.resample('W').agg({'Close': ['last', 'mean', 'max', 'min'], 'Open': 'first'})\n",
    "        weekly_data.columns = weekly_data.columns.map('_'.join).str.strip('_')\n",
    "        weekly_data = self.calculate_variation(weekly_data)\n",
    "        return self.apply_custom_formatting(weekly_data)\n",
    "\n",
    "    def calculate_variation(self, data):\n",
    "        logger.info(\"Calculating variation\")\n",
    "        data['variation_$_abs'] = data['Close_last'] - data['Open_first']\n",
    "        data['variation_%_rel'] = ((data['Close_last'] - data['Open_first']) / data['Open_first']) * 100\n",
    "        return data\n",
    "\n",
    "    def display_all_analyses(self):\n",
    "        logger.info(\"Displaying all analyses\")\n",
    "        all_time_high, all_time_low, all_time_high_date, all_time_low_date = self.get_all_time_records()\n",
    "        print(f\"All Time High: {self.format_and_round(all_time_high)} (Date: {all_time_high_date})\")\n",
    "        print(f\"All Time Low: {self.format_and_round(all_time_low)} (Date: {all_time_low_date})\")\n",
    "\n",
    "        print(\"\\nYearly Analysis:\")\n",
    "        display(self.get_yearly_analysis())\n",
    "\n",
    "        print(\"\\nMonthly Analysis:\")\n",
    "        display(self.get_monthly_analysis())\n",
    "\n",
    "        print(\"\\nWeekly Analysis:\")\n",
    "        display(self.get_weekly_analysis())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63e6cbae",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create an instance of CryptoAnalytics\n",
    "analytics = CryptoAnalytics(crypto)\n",
    "# Display all analyses\n",
    "analytics.display_all_analyses()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5760110b",
   "metadata": {},
   "source": [
    "# ------------------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bd84536",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48d8585a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f183011",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d52ac54",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "crypto = CryptoData(\"BTC\")\n",
    "data = crypto.get_cryptocmd_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfdea9dc",
   "metadata": {},
   "source": [
    "# ------------------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e6a7b43",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TimeSeriesAnalysis:\n",
    "    \"\"\"\n",
    "    This class provides methods for performing time series analysis on cryptocurrency data.\n",
    "\n",
    "    Input:\n",
    "        data (pd.Series or array-like): Time series data to be analyzed.\n",
    "\n",
    "    Methods:\n",
    "        check_stationarity: Checks the stationarity of the time series using the Augmented Dickey-Fuller test.\n",
    "        check_autocorrelation: Plots the autocorrelation and partial autocorrelation functions of the time series.\n",
    "        check_volatility: Fits a GARCH(1,1) model to the time series and prints the model summary.\n",
    "    \"\"\"\n",
    "    def __init__(self, data, target):\n",
    "        logger.info(\"Initializing TimeSeriesAnalysis class\")\n",
    "        self.data = data\n",
    "        self.target = target\n",
    "        \n",
    "    def check_stationarity(self):\n",
    "        logger.info(\"Checking stationarity of the time series\")\n",
    "        result = adfuller(self.data[self.target])\n",
    "        print('ADF Statistic: %f' % result[0])\n",
    "        print('p-value: %f' % result[1])\n",
    "        print('Critical Values:')\n",
    "        for key, value in result[4].items():\n",
    "            print('\\t%s: %.3f' % (key, value))\n",
    "        if result[1] <= 0.05:\n",
    "            print('The series is likely stationary.')\n",
    "        else:\n",
    "            print('The series is likely non-stationary.')\n",
    "\n",
    "    def check_autocorrelation(self):\n",
    "        logger.info(\"Checking autocorrelation of the time series\")\n",
    "        fig, (ax1, ax2) = plt.subplots(1,2, figsize=(20,6))\n",
    "        data1D = self.data[self.target].values   # Convert DataFrame to 1D numpy array\n",
    "        plot_acf(data1D, lags=50, alpha=0.05, ax=ax1)\n",
    "        plt.title(\"ACF for Close Price\", size=20)\n",
    "\n",
    "        plot_pacf(data1D, lags=50, alpha=0.05, method='ols', ax=ax2)\n",
    "        plt.title(\"PACF for Close Price -- Daily\", size=20)\n",
    "\n",
    "\n",
    "    def check_volatility(self):\n",
    "        logger.info(\"Checking volatility of the time series\")\n",
    "        model = arch_model(self.data[self.target], vol='Garch', p=1, q=1)\n",
    "        model_fit = model.fit()\n",
    "        print(model_fit.summary())\n",
    "    \n",
    "    def decompose_time_series(self, model='additive', period=30):\n",
    "        logger.info(\"Decomposing the time series\")\n",
    "        result = seasonal_decompose(self.data[self.target], model=model, period=period)\n",
    "        fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(12, 8))\n",
    "        result.observed.plot(ax=ax1)\n",
    "        ax1.set_title('Observed')\n",
    "        result.trend.plot(ax=ax2)\n",
    "        ax2.set_title('Trend')\n",
    "        result.seasonal.plot(ax=ax3)\n",
    "        ax3.set_title('Seasonal')\n",
    "        result.resid.plot(ax=ax4)\n",
    "        ax4.set_title('Residual')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "    def test_granger_causality(self, other_column, maxlag=30):\n",
    "        logger.info(\"Testing Granger causality\")\n",
    "        other_data = self.data[other_column].values\n",
    "        target_data = self.data[self.target].values\n",
    "        data = np.column_stack((target_data, other_data))\n",
    "        result = grangercausalitytests(data, maxlag=maxlag)\n",
    "        return result\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f09ca3cf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create an instance of the TimeSeriesAnalysis class\n",
    "tsa = TimeSeriesAnalysis(data,target='Close')\n",
    "tsa.check_stationarity()\n",
    "tsa.check_volatility()\n",
    "tsa.check_autocorrelation()\n",
    "tsa.decompose_time_series()\n",
    "tsa.test_granger_causality('Open', maxlag=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c664b553",
   "metadata": {},
   "source": [
    "# ------------------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb0ed077",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class DataPreprocessing:\n",
    "    def __init__(self, data, target_columns, seq_length=5, scaler_path='./scaler.pkl'):\n",
    "        logger.info(\"Initializing DataPreprocessing class\")\n",
    "        \n",
    "        # Check if target_columns exist in data\n",
    "        if not set(target_columns).issubset(data.columns):\n",
    "            logger.error(f\"Target columns {target_columns} not found in data.\")\n",
    "            raise ValueError(f\"Target columns {target_columns} not found in data.\")\n",
    "        \n",
    "        self.data = data.sort_index(ascending=True)\n",
    "        self.target_columns = target_columns\n",
    "        self.seq_length = seq_length\n",
    "        self.scaler = StandardScaler()\n",
    "        self.scaler_path = scaler_path\n",
    "\n",
    "        # If a scaler file exists, load it. Otherwise, fit a new scaler\n",
    "        if os.path.exists(self.scaler_path):\n",
    "            self.load_scaler()\n",
    "            self.data_scaled = self.scaler.transform(self.data[self.target_columns])\n",
    "        else:\n",
    "            self.data_scaled = self.scaler.fit_transform(self.data[self.target_columns])\n",
    "            self.save_scaler()\n",
    "\n",
    "    def save_scaler(self):\n",
    "        logger.info(\"Saving scaler\")\n",
    "        joblib.dump(self.scaler, self.scaler_path)\n",
    "        logger.info(f\"Scaler saved to {self.scaler_path}\")\n",
    "\n",
    "    def load_scaler(self):\n",
    "        logger.info(\"Loading scaler\")\n",
    "        try:\n",
    "            self.scaler = joblib.load(self.scaler_path)\n",
    "            logger.info(f\"Scaler loaded from {self.scaler_path}\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error loading scaler from {self.scaler_path}: {e}\")\n",
    "            raise\n",
    "\n",
    "    def split_data(self, test_size=0.2):\n",
    "        logger.info(\"Splitting data\")\n",
    "        train_data, test_data = train_test_split(self.data_scaled, test_size=test_size, shuffle=False)\n",
    "        return train_data, test_data\n",
    "\n",
    "    def prepare_data_rnn(self, data):\n",
    "        logger.info(\"Preparing data for RNN\")\n",
    "        X, y = [], []\n",
    "        for i in range(self.seq_length, len(data)):\n",
    "            X.append(data[i-self.seq_length:i])\n",
    "            y.append(data[i, 0])\n",
    "        X, y = np.array(X), np.array(y)\n",
    "        logger.info(f\"RNN Data Shape - X: {X.shape}, y: {y.shape}\")\n",
    "        return X, y   \n",
    "\n",
    "    def prepare_data_for_tree_based_model(self, target_column='Close', test_size=0.2, scale=False):\n",
    "        logger.info(\"Preparing data for tree-based model\")\n",
    "        X = self.data.drop(target_column, axis=1)\n",
    "        y = self.data[target_column]\n",
    "\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X, y, test_size=test_size, shuffle=False)\n",
    "\n",
    "        if scale:\n",
    "            scaler = StandardScaler()\n",
    "            X_train = scaler.fit_transform(X_train)\n",
    "            X_test = scaler.transform(X_test)\n",
    "            \n",
    "        logger.info(f\"Tree Data Shape - X: {X_train.shape}, {y_train.shape} , y: {X_test.shape}, {y_test.shape}\")\n",
    "        return X_train, y_train, X_test, y_test\n",
    "\n",
    "    def visualize_split(self, train_data, test_data):\n",
    "        logger.info(\"Visualizing data split\")\n",
    "        plt.figure(figsize=(14, 7))\n",
    "        plt.plot(np.arange(len(train_data)), self.scaler.inverse_transform(train_data)[:, 0], color='blue', label='Training Data')\n",
    "        plt.plot(np.arange(len(train_data), len(train_data) + len(test_data)), self.scaler.inverse_transform(test_data)[:, 0], color='orange', label='Testing Data')\n",
    "        plt.xlabel('Time Step')\n",
    "        plt.ylabel('Normalized Value')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "    def prepare_data_SARIMAX(self, target_column='Close', exog_columns=None, test_size=0.2):\n",
    "        logger.info(\"Preparing data for SARIMAX\")\n",
    "        y = self.data[target_column]\n",
    "        X = self.data[exog_columns] if exog_columns else None\n",
    "\n",
    "        y_train, y_test = train_test_split(y, test_size=test_size, shuffle=False)\n",
    "        X_train, X_test = train_test_split(X, test_size=test_size, shuffle=False) if X is not None else (None, None)\n",
    "\n",
    "        logger.info(f\"SARIMAX Data Shape - y: {y_train.shape}, {y_test.shape}\")\n",
    "        return y_train, y_test, X_train, X_test\n",
    "\n",
    "    def prepare_data_deepar(self):\n",
    "        logger.info(\"Preparing data for DeepAR\")\n",
    "        # Add your preferred method to prepare data for AutoTS model\n",
    "        pass\n",
    "\n",
    "    def prepare_data_deeptime(self):\n",
    "        logger.info(\"Preparing data for DeepTime\")\n",
    "        # Add your preferred method to prepare data for DeepTime model\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4221643f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Assuming 'Close' is your target column\n",
    "preprocessor = DataPreprocessing(data, ['Close'])\n",
    "scaled_data = preprocessor.data_scaled\n",
    "train_data, test_data = preprocessor.split_data(test_size=0.2)\n",
    "#preprocessor.visualize_split(train_data, test_data)\n",
    "X_train_rnn, y_train_rnn = preprocessor.prepare_data_rnn(train_data)\n",
    "X_test_rnn, y_test_rnn = preprocessor.prepare_data_rnn(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daeb15bf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "preprocessor = DataPreprocessing(data, ['Close'])\n",
    "scaled_data = preprocessor.data_scaled\n",
    "train_data, test_data = preprocessor.split_data(test_size=0.2)\n",
    "# For Linear Regression\n",
    "X_train_lr, y_train_lr, X_test_lr, y_test_lr = preprocessor.prepare_data_for_tree_based_model(target_column='Close', test_size=0.2, scale=True)\n",
    "# For XGBoost\n",
    "X_train_xgb, y_train_xgb, X_test_xgb, y_test_xgb = preprocessor.prepare_data_for_tree_based_model(target_column='Close', test_size=0.2, scale=False)\n",
    "# For LightGBM\n",
    "X_train_lgb, y_train_lgb, X_test_lgb, y_test_lgb = preprocessor.prepare_data_for_tree_based_model(target_column='Close', test_size=0.2, scale=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71ad09c8",
   "metadata": {},
   "source": [
    "# ------------------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13729b2e",
   "metadata": {},
   "source": [
    "# Block X - LSTM Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a4ed8c1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class LSTM_Models:\n",
    "    def __init__(self, input_shape, units, dropout, dense_units, optimizer, scaler, X_train, y_train, X_test, y_test,cross_val=False):\n",
    "        logging.info(\"Initializing LSTM model\")\n",
    "        self.model = Sequential()\n",
    "        for i, unit in enumerate(units):\n",
    "            return_sequences = True if i < len(units) - 1 else False\n",
    "            self.model.add(LSTM(units=unit, input_shape=input_shape, return_sequences=return_sequences))\n",
    "            self.model.add(Dropout(dropout))\n",
    "        self.model.add(Dense(units=dense_units))\n",
    "        self.model.compile(optimizer=optimizer, loss='mean_squared_error')\n",
    "        self.model.summary()\n",
    "        self.cross_val = cross_val\n",
    "        self.scaler = scaler\n",
    "        self.X_train = X_train\n",
    "        self.y_train = y_train\n",
    "        self.X_test = X_test\n",
    "        self.y_test = y_test\n",
    "        \n",
    "        self.params = {\n",
    "            'input_shape': input_shape,\n",
    "            'units': units,\n",
    "            'dropout': dropout,\n",
    "            'dense_units': dense_units,\n",
    "            'optimizer': optimizer\n",
    "        }\n",
    "\n",
    "    def train_model(self, epochs=100, batch_size=50, early_stopping=True):\n",
    "        logging.info(\"Training LSTM model\")\n",
    "        callbacks = [EarlyStopping(monitor='val_loss', patience=10)] if early_stopping else None\n",
    "        if self.cross_val:\n",
    "            tscv = TimeSeriesSplit(n_splits=5)\n",
    "            self.history = []\n",
    "            fold_no = 1\n",
    "            for train, val in tscv.split(self.X_train):\n",
    "                logging.info(f\"Training on fold {fold_no}\")\n",
    "                history = self.model.fit(self.X_train[train], self.y_train[train], epochs=epochs, \n",
    "                                         batch_size=batch_size, validation_data=(self.X_train[val], self.y_train[val]), \n",
    "                                         callbacks=callbacks, shuffle=False)\n",
    "                self.history.append(history)\n",
    "                logging.info(f\"Done with fold {fold_no}\")\n",
    "                fold_no += 1\n",
    "        else:\n",
    "            self.history = self.model.fit(self.X_train, self.y_train, epochs=epochs, \n",
    "                                          batch_size=batch_size, validation_split=0.2, \n",
    "                                          callbacks=callbacks, shuffle=False)\n",
    "        logging.info(\"Training completed\")\n",
    "\n",
    "    def make_predictions(self):\n",
    "        logging.info(\"Making predictions with LSTM model\")\n",
    "        self.train_predictions = self.model.predict(self.X_train)\n",
    "        self.test_predictions = self.model.predict(self.X_test)\n",
    "\n",
    "        # Unscaled the predictions\n",
    "        self.train_predictions = self.scaler.inverse_transform(self.train_predictions)\n",
    "        self.test_predictions = self.scaler.inverse_transform(self.test_predictions)\n",
    "\n",
    "        self.train_comparison_df = pd.DataFrame({'Actual': self.scaler.inverse_transform(self.y_train.reshape(-1, 1)).flatten(), \n",
    "                                                 'Predicted': self.train_predictions.squeeze()})\n",
    "        self.test_comparison_df = pd.DataFrame({'Actual': self.scaler.inverse_transform(self.y_test.reshape(-1, 1)).flatten(), \n",
    "                                                'Predicted': self.test_predictions.squeeze()})\n",
    "        logging.info(\"Predictions made\")\n",
    "\n",
    "    def evaluate_model(self):\n",
    "        logging.info(\"Evaluating LSTM model\")\n",
    "        metrics = {'RMSE': mean_squared_error, 'R2 Score': r2_score, \n",
    "                   'MAE': mean_absolute_error, 'Explained Variance': explained_variance_score}\n",
    "\n",
    "        evaluation = {}\n",
    "        for name, metric in metrics.items():\n",
    "            if name == 'RMSE':\n",
    "                train_evaluation = metric(self.train_comparison_df['Actual'], \n",
    "                                          self.train_comparison_df['Predicted'], \n",
    "                                          squared=False)\n",
    "                test_evaluation = metric(self.test_comparison_df['Actual'], \n",
    "                                         self.test_comparison_df['Predicted'], \n",
    "                                         squared=False)\n",
    "            else:\n",
    "                train_evaluation = metric(self.train_comparison_df['Actual'], \n",
    "                                          self.train_comparison_df['Predicted'])\n",
    "                test_evaluation = metric(self.test_comparison_df['Actual'], \n",
    "                                         self.test_comparison_df['Predicted'])\n",
    "            evaluation[name] = {'Train': train_evaluation, 'Test': test_evaluation}\n",
    "\n",
    "        self.evaluation_df = pd.DataFrame(evaluation)\n",
    "        logging.info(\"Evaluation completed\")\n",
    "        return self.evaluation_df\n",
    "\n",
    "    def plot_history(self):\n",
    "        logging.info(\"Plotting training history\")\n",
    "        plt.figure(figsize=(14, 7))\n",
    "\n",
    "        if self.cross_val:\n",
    "            # Loop through the history of each fold\n",
    "            for i, history in enumerate(self.history):\n",
    "                plt.plot(history.history['loss'], label=f'Training Loss Fold {i+1}')\n",
    "                plt.plot(history.history['val_loss'], label=f'Validation Loss Fold {i+1}')\n",
    "        else:\n",
    "            plt.plot(self.history.history['loss'], label='Training Loss')\n",
    "            plt.plot(self.history.history['val_loss'], label='Validation Loss')\n",
    "\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "        logging.info(\"Plotting completed\")\n",
    "\n",
    "    def plot_predictions(self):\n",
    "        logging.info(\"Plotting predictions\")\n",
    "        fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(14, 7))\n",
    "\n",
    "        axes[0].plot(self.train_comparison_df['Actual'], label='Actual')\n",
    "        axes[0].plot(self.train_comparison_df['Predicted'], label='Predicted')\n",
    "        axes[0].set_title('Training Data')\n",
    "        axes[0].legend()\n",
    "\n",
    "        axes[1].plot(self.test_comparison_df['Actual'], label='Actual')\n",
    "        axes[1].plot(self.test_comparison_df['Predicted'], label='Predicted')\n",
    "        axes[1].set_title('Testing Data')\n",
    "        axes[1].legend()\n",
    "\n",
    "        plt.show()\n",
    "        logging.info(\"Plotting completed\")\n",
    "            \n",
    "    def save_model(self):\n",
    "        # Create a model name based on the parameters\n",
    "        model_name = f\"LSTM_model_{str(self.params).replace(' ', '').replace(':', '').replace(',', '_')}.h5\"\n",
    "        model_path = os.path.join(\"trained_models\", model_name)\n",
    "\n",
    "        # Save the model\n",
    "        self.model.save(model_path)\n",
    "        logging.info(f\"Model saved at {model_path}\")\n",
    "\n",
    "    @staticmethod\n",
    "    def load_model(model_path):\n",
    "        # Load the model\n",
    "        loaded_model = load_model(model_path)\n",
    "        logging.info(f\"Model loaded from {model_path}\")\n",
    "        return loaded_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7baaa09",
   "metadata": {},
   "source": [
    "# Block X - LSTM Models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d0bb5fd",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# After preparing your data with the DataPreprocessing class...\n",
    "lstm_model = LSTM_Models(input_shape=(X_train_rnn.shape[1], X_train_rnn.shape[2]), \n",
    "                         units=[256, 128], \n",
    "                         dropout=0.2, \n",
    "                         dense_units=1, \n",
    "                         optimizer='adam', \n",
    "                         scaler=preprocessor.scaler, \n",
    "                         X_train=X_train_rnn, \n",
    "                         y_train=y_train_rnn, \n",
    "                         X_test=X_test_rnn, \n",
    "                         y_test=y_test_rnn,\n",
    "                        cross_val=False)\n",
    "\n",
    "lstm_model.train_model(epochs=100, batch_size=32, early_stopping=True)\n",
    "lstm_model.save_model()  # save the model\n",
    "lstm_model.make_predictions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d08831a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "lstm_model.evaluate_model()\n",
    "lstm_model.plot_history()\n",
    "lstm_model.plot_predictions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bf9b11d",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# After preparing your data with the DataPreprocessing class...\n",
    "lstm_model1 = LSTM_Models(input_shape=(X_train_rnn.shape[1], X_train_rnn.shape[2]), \n",
    "                         units=[256], \n",
    "                         dropout=0.2, \n",
    "                         dense_units=1, \n",
    "                         optimizer='adam', \n",
    "                         scaler=preprocessor.scaler, \n",
    "                         X_train=X_train_rnn, \n",
    "                         y_train=y_train_rnn, \n",
    "                         X_test=X_test_rnn, \n",
    "                         y_test=y_test_rnn)\n",
    "\n",
    "lstm_model1.train_model(epochs=100, batch_size=32, early_stopping=True)\n",
    "lstm_model.save_model()  # save the model\n",
    "lstm_model1.make_predictions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3852a4af",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "lstm_model1.evaluate_model()\n",
    "lstm_model1.plot_history()\n",
    "lstm_model1.plot_predictions()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5d2e2d3",
   "metadata": {},
   "source": [
    "# ------------------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68af47cd-1001-4d00-aeaa-c70d98da978f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Stop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4496fbc3",
   "metadata": {},
   "source": [
    "# Block X - Hardcoded Grid-Search For LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cde081dc",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "best_score = float('inf')\n",
    "best_model = None\n",
    "best_params = None\n",
    "\n",
    "# Define the grid\n",
    "layer_grid = [[30], [50], [30, 30], [50, 50], [30, 50, 30]]\n",
    "\n",
    "for layers in layer_grid:\n",
    "    print(f\"Training model with layers: {layers}\")\n",
    "    \n",
    "    # Train the model\n",
    "    model = LSTM_Models(input_shape=(X_train_rnn.shape[1], X_train_rnn.shape[2]), \n",
    "                        units=layers, \n",
    "                        dropout=0.2, \n",
    "                        dense_units=1, \n",
    "                        optimizer='adam', \n",
    "                        scaler=preprocessor.scaler, \n",
    "                         X_train=X_train_rnn, \n",
    "                         y_train=y_train_rnn, \n",
    "                         X_test=X_test_rnn, \n",
    "                         y_test=y_test_rnn)\n",
    "    model.train_model(epochs=100, batch_size=32, early_stopping=True)\n",
    "    model.make_predictions()\n",
    "    model.evaluate_model()\n",
    "\n",
    "    # Check if this model is the best so far\n",
    "    current_score = model.evaluation_df.loc['Test', 'RMSE']\n",
    "    if current_score < best_score:\n",
    "        best_score = current_score\n",
    "        best_model = model\n",
    "        best_params = layers\n",
    "\n",
    "print(f\"Best model has layers: {best_params} with RMSE: {best_score}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f4a342e",
   "metadata": {},
   "source": [
    "# ------------------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "837de604",
   "metadata": {
    "id": "ce0673a7"
   },
   "source": [
    "# Block X - Keras Tuner Grid-Search For LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92558fa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMHyperModel(HyperModel):\n",
    "    def __init__(self, input_shape, scaler):\n",
    "        self.input_shape = input_shape\n",
    "        self.scaler = scaler\n",
    "\n",
    "    def build(self, hp):\n",
    "        model = Sequential()\n",
    "        for i in range(hp.Int('num_layers', 1, 3)):\n",
    "            model.add(LSTM(units=hp.Int('units_' + str(i), min_value=30, max_value=80, step=10),\n",
    "                           activation=hp.Choice('activation_'+str(i), ['relu', 'tanh']),\n",
    "                           input_shape=self.input_shape,\n",
    "                           return_sequences=True if i < hp.Int('num_layers', 1, 3) - 1 else False))\n",
    "            model.add(Dropout(rate=hp.Float('dropout_'+str(i), min_value=0.0, max_value=0.5, step=0.1)))\n",
    "        model.add(Dense(units=hp.Int('dense_units', 1, 3), activation=hp.Choice('dense_activation', ['relu', 'linear'])))\n",
    "        \n",
    "        model.compile(optimizer=hp.Choice('optimizer', ['adam', 'sgd']),\n",
    "                      loss='mean_squared_error')\n",
    "        \n",
    "        return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ec93940",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "hypermodel = LSTMHyperModel(input_shape=(X_train_rnn.shape[1], X_train_rnn.shape[2]), scaler=preprocessor.scaler)\n",
    "\n",
    "tuner = RandomSearch(\n",
    "    hypermodel,\n",
    "    objective='val_loss',\n",
    "    max_trials=10,  # adjust based on resources\n",
    "    executions_per_trial=2,  # adjust based on resources\n",
    "    directory='random_search',\n",
    "    project_name='lstm'\n",
    ")\n",
    "\n",
    "tuner.search(X_train_rnn, y_train_rnn, epochs=50, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04d63956",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "best_model = tuner.get_best_models()[0]\n",
    "best_hyperparameters = tuner.get_best_hyperparameters()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66a65609",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the best model's architecture\n",
    "best_model.summary()\n",
    "# Display the best hyperparameters\n",
    "print(best_hyperparameters.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5342621d",
   "metadata": {
    "id": "433cff1b"
   },
   "source": [
    "# Block 8 - Linear Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a3e9795",
   "metadata": {},
   "source": [
    "# ------------------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b98c2cb2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Linear_Regression:\n",
    "    def __init__(self, X_train, y_train, X_test, y_test,cross_val=False):\n",
    "        logger.info(\"Initializing Linear_Regression class\")\n",
    "        self.X_train = X_train\n",
    "        self.y_train = y_train\n",
    "        self.X_test = X_test\n",
    "        self.y_test = y_test\n",
    "        self.cross_val = cross_val\n",
    "        self.model = LinearRegression()\n",
    "\n",
    "    def train_model(self):\n",
    "        logger.info(\"Training Linear Regression model\")\n",
    "        \n",
    "        if self.cross_val:\n",
    "            tscv = TimeSeriesSplit(n_splits=5)\n",
    "            fold_no = 1\n",
    "            for train_index, test_index in tscv.split(self.X_train):\n",
    "                logger.info(f\"Performing cross validation on fold {fold_no}\")\n",
    "                cv_train_x, cv_val_x = self.X_train[train_index], self.X_train[test_index]\n",
    "                cv_train_y, cv_val_y = self.y_train[train_index], self.y_train[test_index]\n",
    "                self.model.fit(cv_train_x, cv_train_y)\n",
    "                cv_val_predictions = self.model.predict(cv_val_x)\n",
    "                cv_val_score = mean_squared_error(cv_val_y, cv_val_predictions, squared=False)\n",
    "                logger.info(f\"Cross-validation score on fold {fold_no}: {cv_val_score}\")\n",
    "                fold_no += 1\n",
    "        else:\n",
    "            self.model.fit(self.X_train, self.y_train)\n",
    "\n",
    "    def make_predictions(self):\n",
    "        logger.info(\"Making predictions with Linear Regression model\")\n",
    "        self.train_predictions = self.model.predict(self.X_train)\n",
    "        self.test_predictions = self.model.predict(self.X_test)\n",
    "\n",
    "    def evaluate_model(self):\n",
    "        logger.info(\"Evaluating Linear Regression model\")\n",
    "        metrics = {'RMSE': mean_squared_error, 'R2 Score': r2_score, \n",
    "                   'MAE': mean_absolute_error, 'Explained Variance': explained_variance_score}\n",
    "\n",
    "        evaluation = {}\n",
    "        for name, metric in metrics.items():\n",
    "            if name == 'RMSE':\n",
    "                train_evaluation = metric(self.y_train, self.train_predictions, squared=False)\n",
    "                test_evaluation = metric(self.y_test, self.test_predictions, squared=False)\n",
    "            else:\n",
    "                train_evaluation = metric(self.y_train, self.train_predictions)\n",
    "                test_evaluation = metric(self.y_test, self.test_predictions)\n",
    "            evaluation[name] = {'Train': train_evaluation, 'Test': test_evaluation}\n",
    "\n",
    "        self.evaluation_df = pd.DataFrame(evaluation)\n",
    "        return self.evaluation_df\n",
    "\n",
    "    def plot_predictions(self):\n",
    "        logger.info(\"Plotting predictions\")\n",
    "        fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(14, 7))\n",
    "\n",
    "        ax[0].plot(self.y_train, label='Actual')\n",
    "        ax[0].plot(self.y_train.index, self.train_predictions, label='Predicted')\n",
    "        ax[0].set_title('Train Data: Actual vs Predicted')\n",
    "        ax[0].legend()\n",
    "\n",
    "        ax[1].plot(self.y_test, label='Actual')\n",
    "        ax[1].plot(self.y_test.index, self.test_predictions, label='Predicted')\n",
    "        ax[1].set_title('Test Data: Actual vs Predicted')\n",
    "        ax[1].legend()\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "    def save_model(self):\n",
    "        model_name = \"linear_regression.joblib\"\n",
    "        model_path = os.path.join(\"trained_models\", model_name)\n",
    "\n",
    "        # Save the model\n",
    "        dump(self.model, model_path)\n",
    "        logger.info(f\"Model saved at {model_path}\")\n",
    "\n",
    "    @staticmethod\n",
    "    def load_model(model_path):\n",
    "        # Load the model\n",
    "        loaded_model = load(model_path)\n",
    "        logger.info(f\"Model loaded from {model_path}\")\n",
    "        return loaded_model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "040d6ab6",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "lr_model = Linear_Regression(X_train_lr, y_train_lr, X_test_lr, y_test_lr, cross_val=True)\n",
    "lr_model.train_model()\n",
    "lr_model.save_model()  # save the model\n",
    "lr_model.make_predictions()\n",
    "evaluation_df = lr_model.evaluate_model()\n",
    "print(evaluation_df)\n",
    "lr_model.plot_predictions()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78287772",
   "metadata": {},
   "source": [
    "# ------------------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe143178",
   "metadata": {
    "id": "433cff1b"
   },
   "source": [
    "# Block 8 - XGBoost Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0cf9009",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "\n",
    "class XGBoostModel:\n",
    "    def __init__(self, X_train, y_train, X_test, y_test, cross_val=False):\n",
    "        logger.info(\"Initializing XGBoostModel class\")\n",
    "        self.X_train = X_train\n",
    "        self.y_train = y_train\n",
    "        self.X_test = X_test\n",
    "        self.y_test = y_test\n",
    "        self.cross_val = cross_val\n",
    "        self.model = XGBRegressor(objective='reg:squarederror')\n",
    "\n",
    "    def train_model(self):\n",
    "        logger.info(\"Training XGBoost model\")\n",
    "\n",
    "        if self.cross_val:\n",
    "            tscv = TimeSeriesSplit(n_splits=5)\n",
    "            fold_no = 1\n",
    "            for train_index, test_index in tscv.split(self.X_train):\n",
    "                logger.info(f\"Performing cross validation on fold {fold_no}\")\n",
    "                cv_train_x, cv_val_x = self.X_train.iloc[train_index], self.X_train.iloc[test_index]\n",
    "                cv_train_y, cv_val_y = self.y_train.iloc[train_index], self.y_train.iloc[test_index]\n",
    "                self.model.fit(cv_train_x, cv_train_y)\n",
    "                cv_val_predictions = self.model.predict(cv_val_x)\n",
    "                cv_val_score = mean_squared_error(cv_val_y, cv_val_predictions, squared=False)\n",
    "                logger.info(f\"Cross-validation score on fold {fold_no}: {cv_val_score}\")\n",
    "                fold_no += 1\n",
    "        else:\n",
    "            self.model.fit(self.X_train, self.y_train)\n",
    "\n",
    "    def make_predictions(self):\n",
    "        self.train_predictions = self.model.predict(self.X_train)\n",
    "        self.test_predictions = self.model.predict(self.X_test)\n",
    "\n",
    "    def evaluate_model(self):\n",
    "        metrics = {'RMSE': mean_squared_error, 'R2 Score': r2_score, \n",
    "                   'MAE': mean_absolute_error, 'Explained Variance': explained_variance_score}\n",
    "\n",
    "        evaluation = {}\n",
    "        for name, metric in metrics.items():\n",
    "            if name == 'RMSE':\n",
    "                train_evaluation = metric(self.y_train, self.train_predictions, squared=False)\n",
    "                test_evaluation = metric(self.y_test, self.test_predictions, squared=False)\n",
    "            else:\n",
    "                train_evaluation = metric(self.y_train, self.train_predictions)\n",
    "                test_evaluation = metric(self.y_test, self.test_predictions)\n",
    "            evaluation[name] = {'Train': train_evaluation, 'Test': test_evaluation}\n",
    "\n",
    "        self.evaluation_df = pd.DataFrame(evaluation)\n",
    "        return self.evaluation_df\n",
    "\n",
    "    def plot_predictions(self):\n",
    "        fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(14, 7))\n",
    "\n",
    "        ax[0].plot(self.y_train, label='Actual')\n",
    "        ax[0].plot(self.y_train.index, self.train_predictions, label='Predicted')\n",
    "        ax[0].set_title('Train Data: Actual vs Predicted')\n",
    "        ax[0].legend()\n",
    "\n",
    "        ax[1].plot(self.y_test, label='Actual')\n",
    "        ax[1].plot(self.y_test.index, self.test_predictions, label='Predicted')\n",
    "        ax[1].set_title('Test Data: Actual vs Predicted')\n",
    "        ax[1].legend()\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    def save_model(self):\n",
    "        model_name = \"xgboost_model.joblib\"\n",
    "        model_path = os.path.join(\"trained_models\", model_name)\n",
    "\n",
    "        # Save the model\n",
    "        dump(self.model, model_path)\n",
    "        logger.info(f\"Model saved at {model_path}\")\n",
    "\n",
    "    @staticmethod\n",
    "    def load_model(model_path):\n",
    "        # Load the model\n",
    "        loaded_model = load(model_path)\n",
    "        logger.info(f\"Model loaded from {model_path}\")\n",
    "        return loaded_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd25d7cc",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "xgb_model = XGBoostModel(X_train_xgb, y_train_xgb, X_test_xgb, y_test_xgb,cross_val=False)\n",
    "xgb_model.train_model()\n",
    "xgb_model.save_model()  # save the model\n",
    "xgb_model.make_predictions()\n",
    "evaluation_df = xgb_model.evaluate_model()\n",
    "print(evaluation_df)\n",
    "xgb_model.plot_predictions()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "142d0f93",
   "metadata": {},
   "source": [
    "# ------------------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2bb896a",
   "metadata": {
    "id": "433cff1b"
   },
   "source": [
    "# Block 8 - LightGBM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d650d0b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class LightGBMModel:\n",
    "    def __init__(self, X_train, y_train, X_test, y_test, cross_val=False):\n",
    "        logger.info(\"Initializing LightGBMModel class\")\n",
    "        self.X_train = X_train\n",
    "        self.y_train = y_train\n",
    "        self.X_test = X_test\n",
    "        self.y_test = y_test\n",
    "        self.cross_val = cross_val\n",
    "        self.model = LGBMRegressor()\n",
    "\n",
    "    def train_model(self):\n",
    "        logger.info(\"Training LightGBM model\")\n",
    "\n",
    "        if self.cross_val:\n",
    "            tscv = TimeSeriesSplit(n_splits=5)\n",
    "            fold_no = 1\n",
    "            for train_index, test_index in tscv.split(self.X_train):\n",
    "                logger.info(f\"Performing cross validation on fold {fold_no}\")\n",
    "                cv_train_x, cv_val_x = self.X_train.iloc[train_index], self.X_train.iloc[test_index]\n",
    "                cv_train_y, cv_val_y = self.y_train.iloc[train_index], self.y_train.iloc[test_index]\n",
    "                self.model.fit(cv_train_x, cv_train_y)\n",
    "                cv_val_predictions = self.model.predict(cv_val_x)\n",
    "                cv_val_score = mean_squared_error(cv_val_y, cv_val_predictions, squared=False)\n",
    "                logger.info(f\"Cross-validation score on fold {fold_no}: {cv_val_score}\")\n",
    "                fold_no += 1\n",
    "        else:\n",
    "            self.model.fit(self.X_train, self.y_train)\n",
    "\n",
    "    def make_predictions(self):\n",
    "        logger.info(\"Making predictions with LightGBM model\")\n",
    "        self.train_predictions = self.model.predict(self.X_train)\n",
    "        self.test_predictions = self.model.predict(self.X_test)\n",
    "\n",
    "    def evaluate_model(self):\n",
    "        logger.info(\"Evaluating LightGBM model\")\n",
    "        metrics = {'RMSE': mean_squared_error, 'R2 Score': r2_score, \n",
    "                   'MAE': mean_absolute_error, 'Explained Variance': explained_variance_score}\n",
    "\n",
    "        evaluation = {}\n",
    "        for name, metric in metrics.items():\n",
    "            if name == 'RMSE':\n",
    "                train_evaluation = metric(self.y_train, self.train_predictions, squared=False)\n",
    "                test_evaluation = metric(self.y_test, self.test_predictions, squared=False)\n",
    "            else:\n",
    "                train_evaluation = metric(self.y_train, self.train_predictions)\n",
    "                test_evaluation = metric(self.y_test, self.test_predictions)\n",
    "            evaluation[name] = {'Train': train_evaluation, 'Test': test_evaluation}\n",
    "\n",
    "        self.evaluation_df = pd.DataFrame(evaluation)\n",
    "        return self.evaluation_df\n",
    "\n",
    "    def plot_predictions(self):\n",
    "        logger.info(\"Plotting predictions\")\n",
    "        fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(14, 7))\n",
    "\n",
    "        ax[0].plot(self.y_train, label='Actual')\n",
    "        ax[0].plot(self.y_train.index, self.train_predictions, label='Predicted')\n",
    "        ax[0].set_title('Train Data: Actual vs Predicted')\n",
    "        ax[0].legend()\n",
    "\n",
    "        ax[1].plot(self.y_test, label='Actual')\n",
    "        ax[1].plot(self.y_test.index, self.test_predictions, label='Predicted')\n",
    "        ax[1].set_title('Test Data: Actual vs Predicted')\n",
    "        ax[1].legend()\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    def save_model(self):\n",
    "        model_name = \"lightgbm_model.joblib\"\n",
    "        model_path = os.path.join(\"trained_models\", model_name)\n",
    "\n",
    "        # Save the model\n",
    "        dump(self.model, model_path)\n",
    "        logger.info(f\"Model saved at {model_path}\")\n",
    "\n",
    "    @staticmethod\n",
    "    def load_model(model_path):\n",
    "        # Load the model\n",
    "        loaded_model = load(model_path)\n",
    "        logger.info(f\"Model loaded from {model_path}\")\n",
    "        return loaded_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29d8930e",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "lgb_model = LightGBMModel(X_train_lgb, y_train_lgb, X_test_lgb, y_test_lgb, cross_val=False)\n",
    "lgb_model.train_model()\n",
    "lgb_model.save_model()  # save the model\n",
    "lgb_model.make_predictions()\n",
    "evaluation_df = lgb_model.evaluate_model()\n",
    "print(evaluation_df)\n",
    "lgb_model.plot_predictions()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e500d31",
   "metadata": {},
   "source": [
    "# ------------------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbc17a5c",
   "metadata": {
    "id": "433cff1b"
   },
   "source": [
    "# Block 8 - AutoArima"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39f6bc0e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Assuming 'Close' is your target column\n",
    "preprocessor = DataPreprocessing(data, ['Close'])\n",
    "scaled_data = preprocessor.data_scaled\n",
    "train_data, test_data = preprocessor.split_data(test_size=0.2)\n",
    "y_train, y_test, X_train, X_test = preprocessor.prepare_data_SARIMAX('Close', ['Volume'])\n",
    "y_train, y_test, X_train, X_test = preprocessor.prepare_data_SARIMAX('Close')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "109cca74",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class SARIMAModel:\n",
    "    def __init__(self, train, test, exog_train=None, exog_test=None):\n",
    "        logger.info(\"Initializing SARIMAModel class\")\n",
    "        self.train = train\n",
    "        self.test = test\n",
    "        self.exog_train = exog_train\n",
    "        self.exog_test = exog_test\n",
    "        self.model = None\n",
    "        self.predictions = None\n",
    "\n",
    "    def auto_fit(self, seasonal=True, m=12, trace=True, error_action='ignore', suppress_warnings=True):\n",
    "        logger.info(\"Starting auto_fit...\")\n",
    "        try:\n",
    "            self.model = pm.auto_arima(self.train, exogenous=self.exog_train, seasonal=seasonal, m=m, trace=trace, error_action=error_action, suppress_warnings=suppress_warnings)\n",
    "            logger.info(\"Auto_fit completed successfully.\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Auto_fit failed with error: {e}\")\n",
    "            raise\n",
    "\n",
    "    def make_predictions(self,start, end):\n",
    "        if self.model is None:\n",
    "            logger.error(\"Model not fitted yet.\")\n",
    "            return\n",
    "        logger.info(\"Making predictions...\")\n",
    "        self.predictions = self.model.predict(n_periods=len(self.test), exogenous=self.exog_test)\n",
    "        return self.predictions\n",
    "    \n",
    "    def evaluate_model(self):\n",
    "        if self.model is None or self.predictions is None:\n",
    "            logger.error(\"Model not fitted or predictions not made yet.\")\n",
    "            return\n",
    "        mse = mean_squared_error(self.test, self.predictions)\n",
    "        mae = mean_absolute_error(self.test, self.predictions)\n",
    "        r2 = r2_score(self.test, self.predictions)\n",
    "        \n",
    "        logger.info(f'MSE: {mse}')\n",
    "        logger.info(f'MAE: {mae}')\n",
    "        logger.info(f'R2 Score: {r2}')\n",
    "\n",
    "    def plot_predictions(self):\n",
    "        if self.model is None or self.predictions is None:\n",
    "            logger.error(\"Model not fitted or predictions not made yet.\")\n",
    "            return\n",
    "        logger.info(\"Plotting predictions\")\n",
    "        plt.figure(figsize=(10,5))\n",
    "        plt.plot(self.test, label='Actual')\n",
    "        plt.plot(self.predictions, label='Predicted')\n",
    "        plt.title('Test Data vs Predicted Data')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "    def save_model(self):\n",
    "        model_name = \"sarima_model.joblib\"\n",
    "        model_path = os.path.join(\"trained_models\", model_name)\n",
    "\n",
    "        # Save the model\n",
    "        dump(self.model, model_path)\n",
    "        logger.info(f\"Model saved at {model_path}\")\n",
    "\n",
    "    @staticmethod\n",
    "    def load_model(model_path):\n",
    "        # Load the model\n",
    "        loaded_model = load(model_path)\n",
    "        logger.info(f\"Model loaded from {model_path}\")\n",
    "        return loaded_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6daf04a6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Initialize the SARIMAModel class\n",
    "model = SARIMAModel(y_train, y_test)# Fit the SARIMA model with seasonal set to True and m set to 12 for monthly data\n",
    "model.auto_fit(seasonal=True, m=12)\n",
    "model.save_model()  # save the model\n",
    "# Make predictions for the length of the test set\n",
    "model.make_predictions(start=len(y_train), end=len(y_train) + len(y_test) - 1)\n",
    "# Evaluate the model\n",
    "model.evaluate_model()\n",
    "# Plot the actual vs predicted values\n",
    "model.plot_predictions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4e38df6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class DataPreprocessing:\n",
    "    def __init__(self, data, target_columns, model_name, seq_length=5):\n",
    "        logger.info(\"Initializing DataPreprocessing class\")\n",
    "        \n",
    "        # Check if target_columns exist in data\n",
    "        if not set(target_columns).issubset(data.columns):\n",
    "            logger.error(f\"Target columns {target_columns} not found in data.\")\n",
    "            raise ValueError(f\"Target columns {target_columns} not found in data.\")\n",
    "        \n",
    "        self.data = data.sort_index(ascending=True)\n",
    "        self.target_columns = target_columns\n",
    "        self.seq_length = seq_length\n",
    "        self.scaler = StandardScaler()\n",
    "        self.model_name = model_name\n",
    "        self.scaler_path = f'./assets/scaler_{model_name}.pkl'\n",
    "\n",
    "        # If a scaler file exists, load it. Otherwise, fit a new scaler\n",
    "        if os.path.exists(self.scaler_path):\n",
    "            self.load_scaler()\n",
    "            self.data_scaled = self.scaler.transform(self.data[self.target_columns])\n",
    "        else:\n",
    "            self.data_scaled = self.scaler.fit_transform(self.data[self.target_columns])\n",
    "            self.save_scaler()\n",
    "\n",
    "    def save_scaler(self):\n",
    "        logger.info(\"Saving scaler\")\n",
    "        joblib.dump(self.scaler, self.scaler_path)\n",
    "        logger.info(f\"Scaler saved to {self.scaler_path}\")\n",
    "\n",
    "    def load_scaler(self):\n",
    "        logger.info(\"Loading scaler\")\n",
    "        try:\n",
    "            self.scaler = joblib.load(self.scaler_path)\n",
    "            logger.info(f\"Scaler loaded from {self.scaler_path}\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error loading scaler from {self.scaler_path}: {e}\")\n",
    "            raise\n",
    "\n",
    "    def split_data(self, test_size=0.2):\n",
    "        logger.info(\"Splitting data\")\n",
    "        train_data, test_data = train_test_split(self.data_scaled, test_size=test_size, shuffle=False)\n",
    "        return train_data, test_data\n",
    "\n",
    "    def prepare_data_rnn(self, data):\n",
    "        logger.info(\"Preparing data for RNN\")\n",
    "        X, y = [], []\n",
    "        for i in range(self.seq_length, len(data)):\n",
    "            X.append(data[i-self.seq_length:i])\n",
    "            y.append(data[i, 0])\n",
    "        X, y = np.array(X), np.array(y)\n",
    "        logger.info(f\"RNN Data Shape - X: {X.shape}, y: {y.shape}\")\n",
    "        return X, y   \n",
    "\n",
    "    def prepare_data_for_tree_based_model(self, target_column='Close', test_size=0.2, scale=False):\n",
    "        logger.info(\"Preparing data for tree-based model\")\n",
    "        X = self.data.drop(target_column, axis=1)\n",
    "        y = self.data[target_column]\n",
    "\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X, y, test_size=test_size, shuffle=False)\n",
    "\n",
    "        if scale:\n",
    "            scaler = StandardScaler()\n",
    "            X_train = scaler.fit_transform(X_train)\n",
    "            X_test = scaler.transform(X_test)\n",
    "            \n",
    "        logger.info(f\"Tree Data Shape - X: {X_train.shape}, {y_train.shape} , y: {X_test.shape}, {y_test.shape}\")\n",
    "        return X_train, y_train, X_test, y_test\n",
    "\n",
    "    def visualize_split(self, train_data, test_data):\n",
    "        logger.info(\"Visualizing data split\")\n",
    "        plt.figure(figsize=(14, 7))\n",
    "        plt.plot(np.arange(len(train_data)), self.scaler.inverse_transform(train_data)[:, 0], color='blue', label='Training Data')\n",
    "        plt.plot(np.arange(len(train_data), len(train_data) + len(test_data)), self.scaler.inverse_transform(test_data)[:, 0], color='orange', label='Testing Data')\n",
    "        plt.xlabel('Time Step')\n",
    "        plt.ylabel('Normalized Value')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "    \n",
    "    def prepare_data_prophet(self, target_col, regressor_cols=None, model_type='uni', normalize=False):\n",
    "        logging.info(\"Preparing data for Prophet model\")\n",
    "        if target_col not in self.data.columns:\n",
    "            logger.error(f\"Target column {target_col} not found in data.\")\n",
    "            raise ValueError(f\"Target column {target_col} not found in data.\")\n",
    "        if regressor_cols:\n",
    "            for col in regressor_cols:\n",
    "                if col not in self.data.columns:\n",
    "                    logger.error(f\"Regressor column {col} not found in data.\")\n",
    "                    raise ValueError(f\"Regressor column {col} not found in data.\")\n",
    "        if not isinstance(self.data.index, pd.DatetimeIndex):\n",
    "            logger.error(\"Index of DataFrame is not date.\")\n",
    "            raise ValueError(\"Index of DataFrame is not date.\")\n",
    "\n",
    "        columns_to_keep = ['Date', target_col] + (regressor_cols if regressor_cols else [])\n",
    "        data_prophet = self.data.reset_index()[columns_to_keep].rename(columns={'Date': 'ds', target_col: 'y'})\n",
    "\n",
    "        # Normalize if required\n",
    "        if normalize:\n",
    "            scaler_path = f'./assets/scaler_{model_type}.pkl'  # update the path here\n",
    "            if not os.path.exists(scaler_path):\n",
    "                logger.error(f\"No scaler file found at {scaler_path}\")\n",
    "                raise ValueError(f\"No scaler file found at {scaler_path}\")\n",
    "            scaler = joblib.load(scaler_path)\n",
    "            if regressor_cols:\n",
    "                data_prophet[regressor_cols] = scaler.transform(data_prophet[regressor_cols])\n",
    "            data_prophet['y'] = scaler.transform(data_prophet[['y']])\n",
    "\n",
    "        return data_prophet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b62225f5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "crypto = CryptoData(\"BTC\")\n",
    "data = crypto.get_cryptocmd_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13924042",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Instantiate the DataPreprocessing class\n",
    "target_columns = ['Close']\n",
    "preprocessor_uni = DataPreprocessing(data, target_columns, model_name='prophet_uni')\n",
    "data_prophet_uni = preprocessor_uni.prepare_data_prophet(target_col='Close', model_type='uni', normalize=True)\n",
    "data_prophet_uni"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a875da0f-5bcb-4a66-ab25-cd4fcaab7767",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "crypto = CryptoData(\"BTC\")\n",
    "data = crypto.get_cryptocmd_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "027f7884",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "target_columns = ['Open', 'High', 'Low', 'Volume', 'Market Cap']  # 'Close' excluded\n",
    "preprocessor_multi = DataPreprocessing(data, target_columns, model_name='prophet_multi')\n",
    "preprocessor_multi.save_scaler()  # retrain and save the scaler with 5 columns\n",
    "\n",
    "regressor_cols = ['Open', 'High', 'Low', 'Volume', 'Market Cap','y']\n",
    "data_prophet_multi = preprocessor_multi.prepare_data_prophet(target_col='Close', regressor_cols=regressor_cols, model_type='multi', normalize=True)\n",
    "data_prophet_multi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8bd351c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "crypto = CryptoData(\"BTC\")\n",
    "data = crypto.get_cryptocmd_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35b231bd-132e-42d1-a692-338d044cd3ab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data1 = data.copy()\n",
    "data1 = data1.drop(['Open', 'High', 'Low', 'Volume', 'Market Cap'], axis=True)\n",
    "data1.rename(columns = {'Close':'y'}, inplace = True)\n",
    "data1.index.names = ['ds']\n",
    "data1 = data1.reset_index()\n",
    "data1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78ca175e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from prophet import Prophet\n",
    "\n",
    "# Python\n",
    "m = Prophet()\n",
    "m.fit(data1)\n",
    "# Python\n",
    "future = m.make_future_dataframe(periods=365)\n",
    "future.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a87e5a6f-ffdf-4cbe-9ea9-f4e8f11c7186",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Python\n",
    "forecast = m.predict(future)\n",
    "forecast[['ds', 'yhat', 'yhat_lower', 'yhat_upper']].tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f11f7a96-d270-4769-85dd-b52077bfa40b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig2 = m.plot_components(forecast)\n",
    "fig2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e6fba37-48e3-47a1-bba4-bc2df1e66473",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Python\n",
    "from prophet.plot import plot_plotly, plot_components_plotly\n",
    "\n",
    "plot_plotly(m, forecast)\n",
    "# Python\n",
    "plot_components_plotly(m, forecast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bda28944-922d-4480-94f2-5adc65f3d9e5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Python\n",
    "from prophet.plot import add_changepoints_to_plot\n",
    "fig = m.plot(forecast)\n",
    "a = add_changepoints_to_plot(fig.gca(), m, forecast)\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "249bc0a8-720f-4ac1-bdcd-529565d41038",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff55a3ea-20c3-4d58-a441-da35ef0442f7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66f4ac1d-8ff1-4cca-b90b-a136e68932e9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1689c9bd-9ede-418b-af5b-a8c826c47209",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fd09884-a792-4f02-96bd-7e6112a21ee7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d710c121-914a-4bb6-82a5-c8b9200f55ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1967aaa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from prophet import Prophet\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import joblib\n",
    "import logging\n",
    "\n",
    "class CryptoProphet:\n",
    "    def __init__(self, model_name, data, target_column, regressor_cols=None):\n",
    "        logger.info(\"Initializing Prophet Model\")\n",
    "        self.model_name = model_name\n",
    "        self.data = data\n",
    "        self.target_column = target_column\n",
    "        self.regressor_cols = regressor_cols if regressor_cols else []\n",
    "        self.model = Prophet()\n",
    "        self.model_path = f'./trained_models/model_{model_name}.pkl'\n",
    "        for regressor in self.regressor_cols:\n",
    "            self.model.add_regressor(regressor)\n",
    "        \n",
    "    def train(self):\n",
    "        logger.info(\"Training Prophet Model\")\n",
    "        self.model.fit(self.data)\n",
    "\n",
    "    def save_model(self):\n",
    "        logger.info(\"Saving Prophet Model\")\n",
    "        joblib.dump(self.model, self.model_path)\n",
    "        logger.info(f\"Model saved to {self.model_path}\")\n",
    "\n",
    "    def load_model(self):\n",
    "        logger.info(\"Loading Prophet Model\")\n",
    "        if os.path.exists(self.model_path):\n",
    "            self.model = joblib.load(self.model_path)\n",
    "            logger.info(f\"Model loaded from {self.model_path}\")\n",
    "        else:\n",
    "            logger.error(f\"No model file found at {self.model_path}\")\n",
    "            raise ValueError(f\"No model file found at {self.model_path}\")\n",
    "\n",
    "    def make_future_dataframe(self, periods, freq='D'):\n",
    "        future = self.model.make_future_dataframe(periods=periods, freq=freq)\n",
    "        return future\n",
    "\n",
    "    def predict(self, future):\n",
    "        logger.info(\"Making Predictions\")\n",
    "        forecast = self.model.predict(future)\n",
    "        return forecast\n",
    "\n",
    "    def plot_predictions(self, forecast):\n",
    "        logger.info(\"Plotting Predictions\")\n",
    "        self.model.plot(forecast)\n",
    "        plt.show()\n",
    "\n",
    "    def evaluate(self, forecast):\n",
    "        logger.info(\"Evaluating Model\")\n",
    "        y_true = self.data[self.target_column].values\n",
    "        y_pred = forecast['yhat'].values[:len(y_true)]\n",
    "        mse = mean_squared_error(y_true, y_pred)\n",
    "        mae = mean_absolute_error(y_true, y_pred)\n",
    "        logger.info(f\"MSE: {mse}, MAE: {mae}\")\n",
    "        return mse, mae\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4c22a03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming that data_prophet_uni has been created\n",
    "prophet_uni = CryptoProphet(model_name='prophet_uni', data=data_prophet_uni, target_column='y')\n",
    "prophet_uni.train()\n",
    "prophet_uni.save_model()\n",
    "\n",
    "# Make future dataframe for predictions\n",
    "future = prophet_uni.make_future_dataframe(periods=30)\n",
    "\n",
    "# Predict and plot\n",
    "forecast = prophet_uni.predict(future)\n",
    "prophet_uni.plot_predictions(forecast)\n",
    "\n",
    "# Evaluate model\n",
    "mse, mae = prophet_uni.evaluate(forecast)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fc10c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming that data_prophet_multi has been created\n",
    "prophet_multi = CryptoProphet(model_name='prophet_multi', data=data_prophet_multi, target_column='Close', regressor_cols=['Open', 'High', 'Low', 'Volume', 'Market Cap'])\n",
    "prophet_multi.train()\n",
    "prophet_multi.save_model()\n",
    "\n",
    "# Make future dataframe for predictions\n",
    "future = prophet_multi.make_future_dataframe(periods=30)\n",
    "\n",
    "# Predict and plot\n",
    "forecast = prophet_multi.predict(future)\n",
    "prophet_multi.plot_predictions(forecast)\n",
    "\n",
    "# Evaluate model\n",
    "mse, mae = prophet_multi.evaluate(forecast)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e98ae8e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ac86518-876c-46e4-8f85-fd0e785d5b86",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bac8121-ea24-4e21-9c5d-347b25f0d12c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa744d0f-958f-44e2-a3e4-763f6cc8f091",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f5f7dea-c5d4-43c7-8d73-d2c4d356acd8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47b87a90-5b38-4176-9787-6f056f5a801d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data1 = data.copy()\n",
    "data1 = data1.drop(['Open', 'High', 'Low', 'Volume', 'Market Cap'], axis=True)\n",
    "data1.rename(columns = {'Close':'y'}, inplace = True)\n",
    "data1.index.names = ['ds']\n",
    "data1 = data1.reset_index()\n",
    "data1.rename(columns = {'y':'Close','ds':'Date'}, inplace = True)\n",
    "data1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6a90d45-480e-420d-9a2c-848d12e3dfab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Read the data\n",
    "df = data1.copy()\n",
    "df[\"Date\"] = pd.to_datetime(df[\"Date\"])\n",
    "df[\"Return\"] = df[\"Close\"].pct_change()\n",
    "df[\"Return\"] = df[\"Return\"].fillna(df[\"Return\"].mean())\n",
    "df = df[np.abs(df[\"Return\"] - df[\"Return\"].mean()) <= 3 * df[\"Return\"].std()]\n",
    "\n",
    "# Define the number of states for the Markov chain\n",
    "n_states = 3\n",
    "\n",
    "# Cluster the returns into n_states using k-means algorithm\n",
    "from sklearn.cluster import KMeans\n",
    "kmeans = KMeans(n_clusters=n_states, random_state=0).fit(df[\"Return\"].values.reshape(-1, 1))\n",
    "df[\"State\"] = kmeans.predict(df[\"Return\"].values.reshape(-1, 1))\n",
    "\n",
    "# Plot the states on the price chart\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.plot(df[\"Date\"], df[\"Close\"], label=\"Price\")\n",
    "for i in range(n_states):\n",
    "    plt.scatter(df[df[\"State\"] == i][\"Date\"], df[df[\"State\"] == i][\"Close\"], label=f\"State {i}\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Price\")\n",
    "plt.title(\"BTC Price and States\")\n",
    "plt.show()\n",
    "\n",
    "# Estimate the transition matrix for the Markov chain\n",
    "trans_mat = np.zeros((n_states, n_states))\n",
    "for i in range(n_states):\n",
    "    for j in range(n_states):\n",
    "        # Count the number of transitions from state i to state j\n",
    "        trans_mat[i, j] = len(df[(df[\"State\"].shift(1) == i) & (df[\"State\"] == j)])\n",
    "    # Normalize the row to sum to 1\n",
    "    trans_mat[i, :] = trans_mat[i, :] / trans_mat[i, :].sum()\n",
    "\n",
    "# Print the transition matrix\n",
    "print(\"Transition matrix:\")\n",
    "print(trans_mat)\n",
    "\n",
    "# Define a function to simulate the Markov chain\n",
    "def simulate_markov_chain(trans_mat, start_state, n_steps):\n",
    "    # Initialize an empty list to store the states\n",
    "    states = []\n",
    "    # Set the current state to the start state\n",
    "    current_state = start_state\n",
    "    # Append the current state to the list\n",
    "    states.append(current_state)\n",
    "    # Loop for n_steps times\n",
    "    for _ in range(n_steps):\n",
    "        # Draw a random number between 0 and 1\n",
    "        rand = np.random.rand()\n",
    "        # Find the next state based on the transition matrix and the random number\n",
    "        next_state = np.where(trans_mat[current_state, :].cumsum() > rand)[0][0]\n",
    "        # Set the current state to the next state\n",
    "        current_state = next_state\n",
    "        # Append the current state to the list\n",
    "        states.append(current_state)\n",
    "    # Return the list of states\n",
    "    return states\n",
    "\n",
    "# Simulate the Markov chain for 10 steps starting from state 0\n",
    "sim_states = simulate_markov_chain(trans_mat, start_state=0, n_steps=10)\n",
    "\n",
    "# Print the simulated states\n",
    "print(\"Simulated states:\")\n",
    "print(sim_states)\n",
    "\n",
    "# Calculate the expected return for each state based on the historical data\n",
    "state_returns = df.groupby(\"State\")[\"Return\"].mean()\n",
    "\n",
    "# Print the expected returns\n",
    "print(\"Expected returns:\")\n",
    "print(state_returns)\n",
    "\n",
    "# Calculate the predicted price for each simulated state based on the last price and the expected return\n",
    "last_price = df[\"Close\"].iloc[-1]\n",
    "pred_prices = [last_price]\n",
    "for state in sim_states:\n",
    "    pred_price = pred_prices[-1] * (1 + state_returns[state])\n",
    "    pred_prices.append(pred_price)\n",
    "\n",
    "# Print the predicted prices\n",
    "print(\"Predicted prices:\")\n",
    "print(pred_prices)\n",
    "\n",
    "# Plot the predicted prices on a chart\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.plot(range(len(pred_prices)), pred_prices, marker=\"o\", label=\"Predicted\")\n",
    "plt.xlabel(\"Step\")\n",
    "plt.ylabel(\"Price\")\n",
    "plt.title(\"BTC Price Prediction using Markov Chain\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3867f8ef-9b9d-4bfe-9b54-d6a736d27d86",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "874df80f-d32d-403b-b305-78ba92262fc5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Read the data\n",
    "df = data1.copy()\n",
    "# Convert the date column to datetime format\n",
    "df[\"Date\"] = pd.to_datetime(df[\"Date\"])\n",
    "\n",
    "# Define the smoothing parameter alpha\n",
    "alpha = 0.2\n",
    "\n",
    "# Initialize the first smoothed value as the first price\n",
    "smoothed = [df[\"Close\"].iloc[0]]\n",
    "\n",
    "# Loop through the rest of the prices\n",
    "for i in range(1, len(df)):\n",
    "    # Apply the exponential smoothing formula\n",
    "    smoothed_value = alpha * df[\"Close\"].iloc[i] + (1 - alpha) * smoothed[-1]\n",
    "    # Append the smoothed value to the list\n",
    "    smoothed.append(smoothed_value)\n",
    "\n",
    "# Add the smoothed values as a new column to the dataframe\n",
    "df[\"Smoothed\"] = smoothed\n",
    "\n",
    "# Plot the price and the smoothed values on a chart\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.plot(df[\"Date\"], df[\"Close\"], label=\"Price\")\n",
    "plt.plot(df[\"Date\"], df[\"Smoothed\"], label=\"Smoothed\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Price\")\n",
    "plt.title(\"BTC Price and Exponential Smoothing\")\n",
    "plt.show()\n",
    "\n",
    "# Predict the next price using the last smoothed value\n",
    "pred_price = df[\"Smoothed\"].iloc[-1]\n",
    "\n",
    "# Print the predicted price\n",
    "print(\"Predicted price:\")\n",
    "print(pred_price)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "853dc219-1189-4640-ac7b-e8ae98c528bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "348f6db5-d1cd-4635-b7b3-2503aa169265",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f34baf39-3154-4cde-bc6f-b8cbbabe5e98",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e09f70a-37e9-4f5b-bc2c-e59b10e065ec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data1 = data.copy()\n",
    "data1 = data1.drop(['Open', 'High', 'Low', 'Volume', 'Market Cap'], axis=True)\n",
    "data1.rename(columns = {'Close':'y'}, inplace = True)\n",
    "data1.index.names = ['ds']\n",
    "data1 = data1.reset_index()\n",
    "data1.rename(columns = {'y':'Close','ds':'Date'}, inplace = True)\n",
    "data1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ce12d4a-8e98-460c-a431-85e0bf3df9bf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import packages and dependencies\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "# Load and preprocess the data\n",
    "data1[\"Date\"] = pd.to_datetime(data1[\"Date\"]) # Convert the Date column to datetime format\n",
    "data1 = data1.set_index(\"Date\") # Set the Date column as the index\n",
    "data1 = data1.sort_index() # Sort the data by date\n",
    "data1 = data1[[\"Close\"]] # Select only the Close column\n",
    "\n",
    "# Split the data into train and test sets\n",
    "train_size = int(len(data1) * 0.8) # Use 80% of the data for training\n",
    "train, test = data1[0:train_size], data1[train_size:len(data1)] # Split the data\n",
    "print(\"Train size:\", len(train))\n",
    "print(\"Test size:\", len(test))\n",
    "\n",
    "# Scale the data to the range [0, 1]\n",
    "scaler = MinMaxScaler(feature_range=(0, 1)) # Create a scaler object\n",
    "train_scaled = scaler.fit_transform(train) # Fit and transform the train set\n",
    "test_scaled = scaler.transform(test) # Transform the test set\n",
    "\n",
    "# Define a function to create input-output pairs from a time series\n",
    "def create_dataset(dataset, look_back=1):\n",
    "    X, Y = [], [] # Initialize empty lists for input and output\n",
    "    for i in range(len(dataset) - look_back - 1): # Loop over the dataset\n",
    "        X.append(dataset[i:(i + look_back), 0]) # Append the previous values as input\n",
    "        Y.append(dataset[i + look_back, 0]) # Append the current value as output\n",
    "    return np.array(X), np.array(Y) # Return numpy arrays\n",
    "\n",
    "# Create input-output pairs for train and test sets\n",
    "look_back = 3 # Use 3 previous values to predict the next one\n",
    "X_train, y_train = create_dataset(train_scaled, look_back) # Create train set\n",
    "X_test, y_test = create_dataset(test_scaled, look_back) # Create test set\n",
    "\n",
    "# Reshape the input to fit the MLP model\n",
    "X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], 1) # Add a dimension for features\n",
    "X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], 1) # Add a dimension for features\n",
    "\n",
    "# Define and compile the MLP model\n",
    "model = Sequential() # Create a sequential model\n",
    "model.add(Dense(10, input_shape=(look_back, 1), activation=\"relu\")) # Add a dense layer with 10 neurons and relu activation\n",
    "model.add(Dense(5, activation=\"relu\")) # Add another dense layer with 5 neurons and relu activation\n",
    "model.add(Dense(1)) # Add an output layer with 1 neuron and no activation\n",
    "model.compile(loss=\"mean_squared_error\", optimizer=\"adam\") # Compile the model with MSE loss and adam optimizer\n",
    "\n",
    "# Fit the model on the train set\n",
    "model.fit(X_train, y_train, epochs=50, batch_size=32, verbose=2) # Train the model for 50 epochs with batch size of 32\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "y_pred = model.predict(X_test) # Predict the test set\n",
    "y_pred = y_pred.reshape(y_pred.shape[0], y_pred.shape[1]) # Reshape y_pred to 2D\n",
    "y_pred = scaler.inverse_transform(y_pred) # Inverse transform the predictions to original scale\n",
    "y_test = scaler.inverse_transform([y_test]) # Inverse transform the test set to original scale\n",
    "test_score = mean_squared_error(y_test[0], y_pred[:,0]) # Calculate the MSE score\n",
    "print(\"Test MSE:\", test_score)\n",
    "\n",
    "# Plot the actual and predicted values\n",
    "plt.plot(data1.index[train_size + look_back + 1:], y_test[0], label=\"Actual\") # Plot the actual values\n",
    "plt.plot(data1.index[train_size + look_back + 1:], y_pred[:,0], label=\"Predicted\") # Plot the predicted values\n",
    "plt.xlabel(\"Date\") # Set x-axis label\n",
    "plt.ylabel(\"Close\") # Set y-axis label\n",
    "plt.legend() # Show legend\n",
    "plt.show() # Show plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fce4c99-e349-4fd6-ae6a-cfe7c1a9cdb7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "700bc57c-7ed3-4ac7-ad0a-2b6ccd70c032",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d645d60-8669-4bdb-93c6-da68bd436b77",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b46c40b5-21ab-4778-a989-55de9ce41b8a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%conda install pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c17cb145-2408-40bf-b74e-6f5bc3cc8f6a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aea7da83-1b8f-4222-9f02-8aff06d6952c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pytorch_forecasting'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-863c406d744d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Import packages\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mpytorch_forecasting\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpytorch_forecasting\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTemporalFusionTransformer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pytorch_forecasting'"
     ]
    }
   ],
   "source": [
    "# Import packages\n",
    "import torch\n",
    "import pytorch_forecasting\n",
    "from pytorch_forecasting import TemporalFusionTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "739e8865-b811-40ef-811d-55b5ffccccd0",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'pytorch_forecasting' from 'torch' (/opt/conda/lib/python3.7/site-packages/torch/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-72ac4e132013>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Import packages\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpytorch_forecasting\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpytorch_forecasting\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTemporalFusionTransformer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'pytorch_forecasting' from 'torch' (/opt/conda/lib/python3.7/site-packages/torch/__init__.py)"
     ]
    }
   ],
   "source": [
    "# Import packages\n",
    "import torch\n",
    "import pytorch_forecasting\n",
    "from pytorch_forecasting import TemporalFusionTransformer\n",
    "\n",
    "# Define parameters\n",
    "max_encoder_length = 60 # maximum length of encoder sequence\n",
    "max_prediction_length = 20 # maximum length of prediction sequence\n",
    "hidden_size = 16 # hidden size of TFT model\n",
    "dropout = 0.1 # dropout rate of TFT model\n",
    "learning_rate = 0.01 # learning rate for optimizer\n",
    "weight_decay = 1e-5 # weight decay for optimizer\n",
    "max_epochs = 10 # maximum number of epochs for training\n",
    "\n",
    "# Define time index column and target column\n",
    "time_idx = \"Date\"\n",
    "target = \"Close\"\n",
    "\n",
    "# Define categorical and continuous variables\n",
    "categorical_variables = [] # list of categorical column names, if any\n",
    "continuous_variables = [] # list of continuous column names, if any\n",
    "\n",
    "# Define group ids for each series, if any\n",
    "group_ids = [] # list of group id column names, if any\n",
    "\n",
    "# Create TimeSeriesDataSet from data1 dataframe\n",
    "dataset = pytorch_forecasting.TimeSeriesDataSet(\n",
    "    data=data1,\n",
    "    time_idx=time_idx,\n",
    "    target=target,\n",
    "    group_ids=group_ids,\n",
    "    max_encoder_length=max_encoder_length,\n",
    "    max_prediction_length=max_prediction_length,\n",
    "    categorical_encoders={var: pytorch_forecasting.encoders.NaNLabelEncoder(add_nan=True) for var in categorical_variables},\n",
    "    time_varying_known_categoricals=categorical_variables,\n",
    "    time_varying_known_reals=continuous_variables,\n",
    "    time_varying_unknown_reals=[target],\n",
    "    target_normalizer=pytorch_forecasting.data.encoders.TorchNormalizer(),\n",
    ")\n",
    "\n",
    "# Create dataloaders for training and validation sets\n",
    "train_dataloader = dataset.to_dataloader(train=True, batch_size=32, num_workers=0)\n",
    "val_dataloader = dataset.to_dataloader(train=False, batch_size=32 * 10, num_workers=0)\n",
    "\n",
    "# Create TFT model\n",
    "model = TemporalFusionTransformer.from_dataset(\n",
    "    dataset,\n",
    "    hidden_size=hidden_size,\n",
    "    dropout=dropout,\n",
    "    output_size=dataset.target_normalizer.mean.size(0),\n",
    "    loss=pytorch_forecasting.metrics.RMSE(),\n",
    "    log_interval=10,\n",
    "    reduce_on_plateau_patience=4,\n",
    ")\n",
    "\n",
    "# Create optimizer\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "\n",
    "# Train the model\n",
    "model.fit(train_dataloader, val_dataloader, max_epochs=max_epochs)\n",
    "\n",
    "# Make predictions on new data\n",
    "predictions = model.predict(val_dataloader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bec0fcd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc3faf27",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05a92516",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64e5c0ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f4e31b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "634a5b28",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9f39a71",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04019705",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60141141",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9ee90b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bae181ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78ee7380",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a8cee3a3",
   "metadata": {
    "id": "433cff1b"
   },
   "source": [
    "# Block 8 - FB Prophet Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26e50830",
   "metadata": {},
   "outputs": [],
   "source": [
    "from prophet import Prophet\n",
    "from prophet.diagnostics import cross_validation, performance_metrics\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class ProphetModel:\n",
    "    def __init__(self, df):\n",
    "        df.reset_index(level=0, inplace=True)\n",
    "        self.df = df.rename(columns={\"Date\": \"ds\", \"Close\": \"y\"})\n",
    "        self.model = Prophet()\n",
    "\n",
    "    def train_model(self):\n",
    "        self.model.fit(self.df)\n",
    "\n",
    "    def make_forecast(self, periods):\n",
    "        future = self.model.make_future_dataframe(periods=periods)\n",
    "        forecast = self.model.predict(future)\n",
    "        self.forecast = forecast\n",
    "        return forecast  # Return the forecast DataFrame\n",
    "\n",
    "\n",
    "    def plot_forecast(self):\n",
    "        return self.model.plot(self.forecast)\n",
    "\n",
    "    def evaluate_model(self):\n",
    "        df_cv = cross_validation(self.model, horizon='30 days')\n",
    "        df_p = performance_metrics(df_cv)\n",
    "        \n",
    "        rmse = np.mean(df_p['rmse'])\n",
    "        mae = np.mean(df_p['mae'])\n",
    "        mse = np.mean(df_p['mse'])\n",
    "        r2 = np.mean(df_p['coverage'])\n",
    "\n",
    "        eval_df = pd.DataFrame({\n",
    "            'Metric': ['RMSE', 'MAE', 'MSE', 'R2'],\n",
    "            'Value': [rmse, mae, mse, r2]\n",
    "        })\n",
    "\n",
    "        return eval_df\n",
    "\n",
    "    def plot_residuals(self):\n",
    "        df_res = self.df.copy()\n",
    "        df_res['yhat'] = self.forecast['yhat']\n",
    "        df_res['residuals'] = df_res['y'] - df_res['yhat']\n",
    "        plt.figure(figsize=(10,6))\n",
    "        plt.plot(df_res['ds'], df_res['residuals'], label='Residuals')\n",
    "        plt.title('Residuals over time')\n",
    "        plt.show()\n",
    "    \n",
    "    def get_predictions_df(self, periods):\n",
    "        df_pred = self.make_forecast(periods)\n",
    "        compare_df = df_pred.set_index('ds')[['yhat']].join(self.df.set_index('ds'))\n",
    "        compare_df = compare_df.rename(columns={'yhat': 'Predicted', 'y': 'Actual'})\n",
    "        return compare_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd186c7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of the ProphetModel class\n",
    "univariate_model = ProphetModel(data)\n",
    "# Train the model\n",
    "univariate_model.train_model()\n",
    "# Make a forecast\n",
    "univariate_model.make_forecast(30) # adjust the number of periods as needed\n",
    "# Evaluate the model\n",
    "evaluation = univariate_model.evaluate_model()\n",
    "print(evaluation)\n",
    "# Plot residuals\n",
    "univariate_model.plot_residuals()\n",
    "# Get the predictions DataFrame\n",
    "predictions_df = univariate_model.get_predictions_df(30) # adjust the number of periods as needed\n",
    "print(predictions_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dc9ca5b",
   "metadata": {
    "id": "433cff1b"
   },
   "source": [
    "# Block 9 - AMZ Deep Time Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba0f74b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from gluonts.dataset.common import ListDataset\n",
    "from gluonts.model.deepar import DeepAREstimator\n",
    "from gluonts.trainer import Trainer\n",
    "from gluonts.evaluation.backtest import make_evaluation_predictions\n",
    "\n",
    "class DeepTimeModel:\n",
    "    def __init__(self, df, column_name):\n",
    "        self.df = df\n",
    "        self.column_name = column_name\n",
    "        self.model = None\n",
    "        self.predictor = None\n",
    "        self.forecast = None\n",
    "\n",
    "    def train_model(self, prediction_length):\n",
    "        dataset = ListDataset([{\n",
    "            \"start\": self.df.index[0],\n",
    "            \"target\": self.df[self.column_name]\n",
    "        }], freq = \"D\")\n",
    "        \n",
    "        estimator = DeepAREstimator(freq=\"D\", \n",
    "                                    prediction_length=prediction_length, \n",
    "                                    trainer=Trainer(epochs=10))\n",
    "        self.model = estimator.train(training_data=dataset)\n",
    "    \n",
    "    def get_predictions(self, test_data):\n",
    "        predictor = self.model.predict(test_data)\n",
    "        self.predictor = predictor\n",
    "        return predictor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26504bdb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create an instance of the DeepTimeModel class\n",
    "deeptime_model = DeepTimeModel(df, 'column_name')\n",
    "# Train the model\n",
    "deeptime_model.train_model(prediction_length=30)\n",
    "# Get the predictions\n",
    "predictions = deeptime_model.get_predictions(test_data)\n"
   ]
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   }
  ],
  "colab": {
   "provenance": []
  },
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:eu-north-1:243637512696:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
